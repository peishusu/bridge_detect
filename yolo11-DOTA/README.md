# åŸºäºyolo11å’Œyolov8çš„é¥æ„Ÿç›®æ ‡æ£€æµ‹

ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³

è§†é¢‘åœ°å€ï¼š[æ‰‹æŠŠæ‰‹æ•™ä½ ä½¿ç”¨YOLO11å®ç°è½¦è¾†æ£€æµ‹ä¸è¿½è¸ªç³»ç»Ÿ_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1nzzdYwE2g/)

ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³ğŸ¥³

å„ä½å°ä¼™ä¼´ï¼Œå¤§å®¶å¥½ï¼Œè¿™é‡Œæ˜¯è‚†åäºŒï¼Œyolo11ç³»åˆ—æˆ‘ä»¬å·²ç»æ›´æ–°äº†å¾ˆå¤šæœŸï¼Œæ¯æœŸçš„èµ„æºä¸­æˆ‘ä»¬ä¸ä»…ä»…æä¾›äº†yolo11çš„æ¨¡å‹ï¼Œè¿˜æä¾›äº†v5ä»¥åŠv8ç­‰æ¨¡å‹æ–¹ä¾¿å¤§å®¶è¿›è¡Œæ¯”è¾ƒã€‚æœ¬æœŸæˆ‘ä»¬è¿›è¡Œçš„æ˜¯æ°´å¹³æ¡†é¥æ„Ÿç›®æ ‡æ£€æµ‹ï¼Œä½¿ç”¨çš„æ˜¯é¥æ„Ÿçš„æ•°æ®é›†ï¼ŒåŒ…å«çš„ç±»åˆ«å¦‚ä¸‹ï¼ŒåŒ…å«2wå¼ å›¾åƒã€‚

* small-vehicle           å°å‹è½¦è¾†  
* large-vehicle           å¤§å‹è½¦è¾† 
* plane                   é£æœº 
* storage-tank            å‚¨æ²¹ç½ 
* ship                    èˆ¹èˆ¶ 
* harbor                  æ¸¯å£ 
* ground-track-field      åœ°é¢è·‘é“ 
* soccer-ball-field       è¶³çƒåœº 
* tennis-court            ç½‘çƒåœº 
* swimming-pool           æ¸¸æ³³æ±  
* baseball-diamond        æ£’çƒåœº 
* roundabout              ç¯å²› 
* basketball-court        ç¯®çƒåœº 
* bridge                  æ¡¥æ¢ 
* helicopter              ç›´å‡æœº

ä»¥ä¸‹æ˜¯éƒ¨åˆ†æ•°æ®ç¤ºä¾‹ã€‚

![39-dota_train_batch88650](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/39-dota_train_batch88650.jpg)

ä¸‹é¢æ˜¯éƒ¨åˆ†å®ç°æ•ˆæœï¼Œæ”¯æŒè§†é¢‘å’Œå›¾åƒæ£€æµ‹ã€‚

![image-20250301021944298](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250301021944298.png)

![image-20250301022008259](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250301022008259.png)

## é¡¹ç›®å®æˆ˜

è¿›è¡Œé¡¹ç›®å®æˆ˜ä¹‹å‰è¯·åŠ¡å¿…å®‰è£…å¥½pytorchå’Œminicondaã€‚

ä¸ä¼šçš„å°ä¼™ä¼´è¯·çœ‹è¿™é‡Œï¼š[Pythoné¡¹ç›®é…ç½®å‰çš„å‡†å¤‡å·¥ä½œ-CSDNåšå®¢](https://blog.csdn.net/ECHOSON/article/details/144233262?sharetype=blogdetail&sharerId=144233262&sharerefer=PC&sharesource=ECHOSON&spm=1011.2480.3001.8118)

<font color='red'>é…ç½®ä¹‹å‰é¦–å…ˆéœ€è¦ä¸‹è½½é¡¹ç›®èµ„æºåŒ…ï¼Œé¡¹ç›®èµ„æºåŒ…è¯·çœ‹ä»ä¸Šæ–¹è§†é¢‘çš„ç½®é¡¶è¯„è®ºä¸­æˆ–è€…æ˜¯åšå®¢ç»‘å®šèµ„æºè·å–å³å¯ã€‚</font>

![image-20250111195350376](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250111195350376.png)

### ç¯å¢ƒé…ç½®

ç¯å¢ƒé…ç½®è¯·çœ‹è¿™é‡Œï¼š[ã€è‚†åäºŒã€‘YOLOç³»åˆ—ä»£ç ç¯å¢ƒé…ç½®ç»Ÿä¸€æµç¨‹-CSDNåšå®¢](https://blog.csdn.net/ECHOSON/article/details/145405669)

### æœ¬åœ°æ¨¡å‹è®­ç»ƒ

æ¨¡å‹è®­ç»ƒä½¿ç”¨çš„è„šæœ¬ä¸º` step1_start_train.py `ï¼Œè¿›è¡Œæ¨¡å‹è®­ç»ƒä¹‹å‰ï¼Œè¯·å…ˆæŒ‰ç…§é…ç½®å¥½ä½ æœ¬åœ°çš„æ•°æ®é›†ã€‚æ•°æ®é›†åœ¨` ultralytics\cfg\datasets\A_my_data.yaml`ç›®å½•ä¸‹ï¼Œä½ éœ€è¦å°†æ•°æ®é›†çš„æ ¹ç›®å½•æ›´æ¢ä¸ºä½ è‡ªå·±æœ¬åœ°çš„ç›®å½•ã€‚

![image-20241204100852481](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204100852481.png)

![image-20250109222911440](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250109222911440.png)

æ›´æ¢ä¹‹åä¿®æ”¹è®­ç»ƒè„šæœ¬é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œç›´æ¥å³é”®å³å¯å¼€å§‹è®­ç»ƒã€‚

![image-20250109223259429](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250109223259429.png)

è®­ç»ƒå¼€å§‹å‰å¦‚æœå‡ºç°æŠ¥é”™ï¼Œæœ‰å¾ˆå¤§çš„å¯èƒ½æ˜¯æ•°æ®é›†çš„è·¯å¾„æ²¡æœ‰é…ç½®æ­£ç¡®ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†çš„è·¯å¾„ï¼Œä¿è¯æ•°æ®é›†é…ç½®æ²¡æœ‰é—®é¢˜ã€‚è®­ç»ƒä¹‹åçš„ç»“æœå°†ä¼šä¿å­˜åœ¨runsç›®å½•ä¸‹ã€‚

![image-20241204101214326](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204101214326.png)

### GPUæœåŠ¡å™¨è®­ç»ƒï¼ˆå¯é€‰ï¼‰

ç›®å‰è“è€˜GPUå¯ä»¥è–…ç¾Šæ¯›ï¼Œæ¨èå°ä¼™ä¼´ä»è¿™ä¸ªç½‘ç«™ä½¿ç”¨GPUäº‘æ¥è¿›è¡Œè®­ç»ƒï¼Œæ–°ç”¨æˆ·æ³¨å†Œä¼šè·å¾—30å…ƒçš„ä»£é‡‘åˆ¸ã€‚

æ³¨å†Œåœ°å€ï¼š[è“è€˜GPUæ™ºç®—äº‘å¹³å°](https://cloud.lanyun.net/#/registerPage?promoterCode=0118 )

æœåŠ¡å™¨ä½¿ç”¨æŒ‡å—ï¼š[æ‰‹æŠŠæ‰‹æ•™ä½ ä½¿ç”¨æœåŠ¡å™¨è®­ç»ƒAIæ¨¡å‹_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV1TuxLeVED6?vd_source=2f9a4e63109c3db3be5e8078e5111776&spm_id_from=333.788.videopod.sections)

### æ¨¡å‹æµ‹è¯•

æ¨¡å‹çš„æµ‹è¯•ä¸»è¦æ˜¯å¯¹mapã€pã€rç­‰æŒ‡æ ‡è¿›è¡Œè®¡ç®—ï¼Œä½¿ç”¨çš„è„šæœ¬ä¸º` step2_start_val.py`ï¼Œæ¨¡å‹åœ¨è®­ç»ƒçš„æœ€åä¸€è½®å·²ç»æ‰§è¡Œäº†æµ‹è¯•ï¼Œå…¶å®è¿™ä¸ªæ­¥éª¤å®Œå…¨å¯ä»¥è·³è¿‡ï¼Œä½†æ˜¯æœ‰çš„æœ‹å‹å¯èƒ½æƒ³è¦å•ç‹¬éªŒè¯ï¼Œé‚£ä½ åªéœ€è¦æ›´æ”¹æµ‹è¯•è„šæœ¬ä¸­çš„æƒé‡ä¸ºä½ è‡ªå·±æ‰€è®­ç»ƒçš„æƒé‡è·¯å¾„ï¼Œå³å¯å•ç‹¬è¿›è¡Œæµ‹è¯•ã€‚

![image-20241204101429118](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204101429118.png)

### å›¾å½¢åŒ–ç•Œé¢å°è£…

å›¾å½¢åŒ–ç•Œé¢è¿›è¡Œäº†å‡çº§ï¼Œæœ¬æ¬¡å›¾å½¢åŒ–ç•Œé¢çš„å¼€å‘æˆ‘ä»¬ä½¿ç”¨pyside6æ¥è¿›è¡Œå¼€å‘ã€‚**PySide6** æ˜¯ä¸€ä¸ªå¼€æºçš„Pythonåº“ï¼Œå®ƒæ˜¯Qt 6æ¡†æ¶çš„Pythonç»‘å®šã€‚Qt æ˜¯ä¸€ä¸ªè·¨å¹³å°çš„åº”ç”¨ç¨‹åºå¼€å‘æ¡†æ¶ï¼Œä¸»è¦ç”¨äºå¼€å‘å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰åº”ç”¨ç¨‹åºï¼ŒåŒæ—¶ä¹Ÿæä¾›äº†ä¸°å¯Œçš„åŠŸèƒ½æ¥å¤„ç†éå›¾å½¢åº”ç”¨ç¨‹åºçš„ä»»åŠ¡ï¼ˆå¦‚æ•°æ®åº“ã€ç½‘ç»œç¼–ç¨‹ç­‰ï¼‰ã€‚PySide6 ä½¿å¾—å¼€å‘è€…èƒ½å¤Ÿä½¿ç”¨ Python ç¼–å†™ Qt 6 åº”ç”¨ç¨‹åºï¼Œå› æ­¤ï¼Œå®ƒæä¾›äº†Pythonçš„çµæ´»æ€§å’ŒQt 6çš„å¼ºå¤§åŠŸèƒ½ã€‚å›¾å½¢åŒ–ç•Œé¢æä¾›äº†å›¾ç‰‡å’Œè§†é¢‘æ£€æµ‹ç­‰å¤šä¸ªåŠŸèƒ½ï¼Œå›¾å½¢åŒ–ç•Œé¢çš„ç¨‹åºä¸º` step3_start_window_track.py `ã€‚

å¦‚æœä½ é‡æ–°è®­ç»ƒäº†æ¨¡å‹ï¼Œéœ€è¦æ›¿æ¢ä¸ºä½ è‡ªå·±çš„æ¨¡å‹ï¼Œè¯·åœ¨è¿™é‡Œè¿›è¡Œæ“ä½œã€‚

![image-20241204101842858](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204101842858.png)

å¦‚æœä½ æƒ³è¦å¯¹å›¾å½¢åŒ–ç•Œé¢çš„é¢˜ç›®ã€logoç­‰è¿›è¡Œä¿®æ”¹ï¼Œç›´æ¥åœ¨è¿™é‡Œä¿®æ”¹å…¨å±€å˜é‡å³å¯ã€‚

![image-20241204101949741](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241204101949741.png)

ç™»å½•ä¹‹åä¸Šä¼ å›¾åƒæˆ–è€…æ˜¯ä¸Šä¼ è§†é¢‘è¿›è¡Œæ£€æµ‹å³å¯ã€‚

![image-20250301022310633](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250301022310633.png)

![image-20241211204753525](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241211204753525.png)

å¯¹äºwebç•Œé¢çš„å°è£…ï¼Œå¯¹åº”çš„pythonæ–‡ä»¶æ˜¯`web_demo.py`ï¼Œæˆ‘ä»¬ä¸»è¦ä½¿ç”¨gradioæ¥è¿›è¡Œå¼€å‘ï¼Œgradioï¼Œè¯¦ç»†çš„ä»£ç å¦‚ä¸‹ï¼š

```python
#!/usr/bin/env python
# -*- coding: UTF-8 -*-
'''
@Project ï¼šstep3_start_window_track.py 
@File    ï¼šweb_demo.py
@IDE     ï¼šPyCharm 
@Author  ï¼šè‚†åäºŒï¼ˆä»˜è´¹å’¨è¯¢QQ: 3045834499ï¼‰ ç²‰ä¸å¯äº«å—99å…ƒè°ƒè¯•æœåŠ¡
@Description  ï¼šTODO æ·»åŠ æ–‡ä»¶æè¿°
@Date    ï¼š2024/12/11 20:25 
'''
import gradio as gr
import PIL.Image as Image

from ultralytics import ASSETS, YOLO

model = YOLO("runs/yolo11s/weights/best.pt")


def predict_image(img, conf_threshold, iou_threshold):
    """Predicts objects in an image using a YOLO11 model with adjustable confidence and IOU thresholds."""
    results = model.predict(
        source=img,
        conf=conf_threshold,
        iou=iou_threshold,
        show_labels=True,
        show_conf=True,
        imgsz=640,
    )

    for r in results:
        im_array = r.plot()
        im = Image.fromarray(im_array[..., ::-1])

    return im


iface = gr.Interface(
    fn=predict_image,
    inputs=[
        gr.Image(type="pil", label="Upload Image"),
        gr.Slider(minimum=0, maximum=1, value=0.25, label="Confidence threshold"),
        gr.Slider(minimum=0, maximum=1, value=0.45, label="IoU threshold"),
    ],
    outputs=gr.Image(type="pil", label="Result"),
    title="åŸºäºYOLO11çš„åƒåœ¾æ£€æµ‹ç³»ç»Ÿ",
    description="Upload images for inference.",
    # examples=[
    #     [ASSETS / "bus.jpg", 0.25, 0.45],
    #     [ASSETS / "zidane.jpg", 0.25, 0.45],
    # ],
)

if __name__ == "__main__":
    # iface.launch(share=True)
    # iface.launch(share=True)
    iface.launch()
```

## æ–‡æ¡£

### èƒŒæ™¯ä¸æ„ä¹‰

é¥æ„ŸæŠ€æœ¯ä½œä¸ºè·å–åœ°çƒè¡¨é¢ä¿¡æ¯çš„é‡è¦æ‰‹æ®µï¼Œåœ¨èµ„æºç›‘æµ‹ã€ç¯å¢ƒè¯„ä¼°ã€åŸå¸‚è§„åˆ’ã€ç¾å®³é¢„è­¦ç­‰é¢†åŸŸå‘æŒ¥ç€ä¸å¯æ›¿ä»£çš„ä½œç”¨ã€‚éšç€é¥æ„Ÿå½±åƒåˆ†è¾¨ç‡çš„ä¸æ–­æé«˜ä»¥åŠæ•°æ®è·å–èƒ½åŠ›çš„å¢å¼ºï¼Œé¥æ„Ÿå½±åƒä¸­åŒ…å«äº†ä¸°å¯Œçš„åœ°ç‰©ä¿¡æ¯ï¼Œå¦‚ä½•é«˜æ•ˆã€å‡†ç¡®åœ°ä»æµ·é‡é¥æ„Ÿæ•°æ®ä¸­æå–ç›®æ ‡ä¿¡æ¯æˆä¸ºå½“å‰ç ”ç©¶çš„é‡ç‚¹ã€‚ä¼ ç»Ÿé¥æ„Ÿç›®æ ‡æ£€æµ‹æ–¹æ³•ä¸»è¦ä¾èµ–äººå·¥è§£è¯‘æˆ–åŸºäºè§„åˆ™çš„å›¾åƒå¤„ç†æŠ€æœ¯ï¼Œå­˜åœ¨æ•ˆç‡ä½ã€ç²¾åº¦å·®ã€é€‚åº”æ€§å¼±ç­‰é—®é¢˜ï¼Œéš¾ä»¥æ»¡è¶³å¤§è§„æ¨¡ã€å®æ—¶æ€§æ£€æµ‹çš„éœ€æ±‚ã€‚

è¿‘å¹´æ¥ï¼Œæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºç›®æ ‡æ£€æµ‹é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çªç ´ï¼Œå°¤å…¶æ˜¯ä»¥YOLOï¼ˆYou Only Look Onceï¼‰ç³»åˆ—ä¸ºä»£è¡¨çš„å®æ—¶ç›®æ ‡æ£€æµ‹ç®—æ³•ï¼Œå› å…¶é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§è€Œå¤‡å—å…³æ³¨ã€‚YOLOv8å’ŒYOLOv11ä½œä¸ºYOLOç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ï¼Œåœ¨æ¨¡å‹ç»“æ„ã€è®­ç»ƒç­–ç•¥å’Œæ£€æµ‹æ€§èƒ½ä¸Šå‡æœ‰æ˜¾è‘—ä¼˜åŒ–ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å¤æ‚åœºæ™¯ä¸‹çš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡ã€‚å°†YOLOv8å’ŒYOLOv11åº”ç”¨äºé¥æ„Ÿç›®æ ‡æ£€æµ‹ï¼Œèƒ½å¤Ÿå®ç°å¯¹é¥æ„Ÿå½±åƒä¸­å¤šç§åœ°ç‰©ç›®æ ‡çš„å¿«é€Ÿã€å‡†ç¡®è¯†åˆ«ï¼Œä¸ºé¥æ„Ÿæ•°æ®çš„æ™ºèƒ½åŒ–å¤„ç†æä¾›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚

åŸºäºYOLOv8å’ŒYOLOv11çš„é¥æ„Ÿç›®æ ‡æ£€æµ‹ç³»ç»Ÿå…·æœ‰é‡è¦çš„ç†è®ºä»·å€¼å’Œå®é™…åº”ç”¨æ„ä¹‰ã€‚é¦–å…ˆï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæ˜¾è‘—æé«˜é¥æ„Ÿç›®æ ‡æ£€æµ‹çš„æ•ˆç‡å’Œç²¾åº¦ï¼Œä¸ºèµ„æºç›‘æµ‹ã€ç¯å¢ƒè¯„ä¼°ã€ç¾å®³é¢„è­¦ç­‰é¢†åŸŸæä¾›å¯é çš„æ•°æ®æ”¯æŒã€‚å…¶æ¬¡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œè¯¥ç³»ç»Ÿå…·æœ‰æ›´é«˜çš„è‡ªåŠ¨åŒ–ç¨‹åº¦å’Œæ›´ä½çš„æˆæœ¬ï¼Œèƒ½å¤Ÿå¤§å¹…å‡å°‘äººå·¥è§£è¯‘çš„å·¥ä½œé‡ï¼Œæé«˜æ•°æ®å¤„ç†æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒYOLOv8å’ŒYOLOv11åœ¨æ¨¡å‹è½»é‡åŒ–å’Œæ£€æµ‹é€Ÿåº¦ä¸Šçš„ä¼˜åŠ¿ï¼Œä½¿å¾—è¯¥ç³»ç»Ÿèƒ½å¤Ÿé€‚åº”å®æ—¶æ€§è¦æ±‚è¾ƒé«˜çš„åº”ç”¨åœºæ™¯ï¼Œå¦‚ç¾å®³åº”æ€¥å“åº”ã€åŠ¨æ€ç›®æ ‡è·Ÿè¸ªç­‰ã€‚

ä»æŠ€æœ¯åˆ›æ–°çš„è§’åº¦æ¥çœ‹ï¼Œè¯¥ç ”ç©¶å°†æ¨åŠ¨æ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨é¥æ„Ÿé¢†åŸŸçš„è¿›ä¸€æ­¥åº”ç”¨ï¼Œä¸ºé¥æ„Ÿå½±åƒçš„æ™ºèƒ½åŒ–å¤„ç†æä¾›æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚åŒæ—¶ï¼Œé€šè¿‡ä¼˜åŒ–æ¨¡å‹æ€§èƒ½å’Œé€‚åº”é¥æ„Ÿå½±åƒçš„ç‰¹ç‚¹ï¼Œèƒ½å¤Ÿä¸ºå…¶ä»–é¢†åŸŸçš„å›¾åƒæ£€æµ‹ä»»åŠ¡æä¾›å€Ÿé‰´å’Œå‚è€ƒã€‚ä»å®é™…åº”ç”¨çš„è§’åº¦æ¥çœ‹ï¼Œè¯¥ç³»ç»Ÿçš„å¼€å‘å°†ä¸ºåŸå¸‚è§„åˆ’ã€å†œä¸šç›‘æµ‹ã€ç”Ÿæ€ä¿æŠ¤ç­‰é¢†åŸŸçš„å†³ç­–æä¾›ç§‘å­¦ä¾æ®ï¼Œæ¨åŠ¨é¥æ„ŸæŠ€æœ¯åœ¨ç¤¾ä¼šç»æµå‘å±•ä¸­çš„å¹¿æ³›åº”ç”¨ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼ŒåŸºäºYOLOv8å’ŒYOLOv11çš„é¥æ„Ÿç›®æ ‡æ£€æµ‹ç³»ç»Ÿä¸ä»…èƒ½å¤Ÿæå‡é¥æ„Ÿæ•°æ®å¤„ç†çš„æ™ºèƒ½åŒ–æ°´å¹³ï¼Œè¿˜èƒ½å¤Ÿä¸ºå¤šé¢†åŸŸçš„å®é™…åº”ç”¨æä¾›æŠ€æœ¯æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„ç ”ç©¶ä»·å€¼å’Œç¤¾ä¼šæ„ä¹‰ã€‚

### ç›¸å…³æ–‡çŒ®ç»¼è¿°

é¥æ„Ÿç›®æ ‡æ£€æµ‹æ˜¯é¥æ„ŸæŠ€æœ¯åº”ç”¨ä¸­çš„æ ¸å¿ƒä»»åŠ¡ä¹‹ä¸€ï¼Œæ—¨åœ¨ä»é¥æ„Ÿå½±åƒä¸­è¯†åˆ«å’Œå®šä½ç‰¹å®šåœ°ç‰©ç›®æ ‡ã€‚éšç€é¥æ„Ÿå½±åƒåˆ†è¾¨ç‡çš„æé«˜å’Œæ•°æ®è·å–èƒ½åŠ›çš„å¢å¼ºï¼Œä¼ ç»Ÿæ–¹æ³•å¦‚äººå·¥è§£è¯‘å’ŒåŸºäºè§„åˆ™çš„å›¾åƒå¤„ç†æŠ€æœ¯å·²éš¾ä»¥æ»¡è¶³å¤§è§„æ¨¡ã€é«˜ç²¾åº¦çš„æ£€æµ‹éœ€æ±‚ã€‚è¿‘å¹´æ¥ï¼Œæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºç›®æ ‡æ£€æµ‹é¢†åŸŸå¸¦æ¥äº†æ–°çš„çªç ´ï¼Œå°¤å…¶æ˜¯ä»¥YOLOï¼ˆYou Only Look Onceï¼‰ç³»åˆ—ä¸ºä»£è¡¨çš„å®æ—¶ç›®æ ‡æ£€æµ‹ç®—æ³•ï¼Œå› å…¶é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§åœ¨é¥æ„Ÿç›®æ ‡æ£€æµ‹ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚

åœ¨é¥æ„Ÿç›®æ ‡æ£€æµ‹é¢†åŸŸï¼Œæ—©æœŸç ”ç©¶ä¸»è¦åŸºäºä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå¦‚æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰å’Œéšæœºæ£®æ—ï¼ˆRandom Forestï¼‰ï¼Œè¿™äº›æ–¹æ³•ä¾èµ–äºæ‰‹å·¥æå–çš„ç‰¹å¾ï¼Œéš¾ä»¥é€‚åº”å¤æ‚åœºæ™¯ä¸‹çš„æ£€æµ‹ä»»åŠ¡ã€‚éšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å…´èµ·ï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰é€æ¸æˆä¸ºä¸»æµæ–¹æ³•ã€‚Faster R-CNNã€SSDå’ŒYOLOç­‰ç›®æ ‡æ£€æµ‹ç®—æ³•åœ¨é¥æ„Ÿå½±åƒä¸­çš„åº”ç”¨æ˜¾è‘—æé«˜äº†æ£€æµ‹ç²¾åº¦å’Œæ•ˆç‡ã€‚YOLOç³»åˆ—ç®—æ³•å› å…¶å•é˜¶æ®µæ£€æµ‹æ¶æ„å’Œå®æ—¶æ€§ä¼˜åŠ¿ï¼Œåœ¨é¥æ„Ÿç›®æ ‡æ£€æµ‹ä¸­è¡¨ç°å‡ºè‰²ã€‚ä¾‹å¦‚ï¼Œæœ‰ç ”ç©¶åŸºäºYOLOv3å®ç°äº†é¥æ„Ÿå½±åƒä¸­è½¦è¾†ã€å»ºç­‘ç‰©ç­‰ç›®æ ‡çš„æ£€æµ‹ï¼ŒéªŒè¯äº†YOLOç®—æ³•åœ¨é¥æ„Ÿé¢†åŸŸçš„é€‚ç”¨æ€§ã€‚

YOLOv8å’ŒYOLOv11ä½œä¸ºYOLOç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ï¼Œåœ¨æ¨¡å‹ç»“æ„ã€è®­ç»ƒç­–ç•¥å’Œæ£€æµ‹æ€§èƒ½ä¸Šå‡æœ‰æ˜¾è‘—ä¼˜åŒ–ã€‚YOLOv8é€šè¿‡å¼•å…¥æ›´é«˜æ•ˆçš„éª¨å¹²ç½‘ç»œå’Œä¼˜åŒ–æŸå¤±å‡½æ•°ï¼Œè¿›ä¸€æ­¥æå‡äº†æ£€æµ‹ç²¾åº¦å’Œé€Ÿåº¦ã€‚YOLOv11åˆ™åœ¨æ¨¡å‹è½»é‡åŒ–å’Œå¤šå°ºåº¦ç‰¹å¾èåˆæ–¹é¢è¿›è¡Œäº†æ”¹è¿›ï¼Œä½¿å…¶æ›´é€‚åˆå¤„ç†å¤æ‚åœºæ™¯ä¸‹çš„é¥æ„Ÿå½±åƒã€‚è¿™äº›æ”¹è¿›ä¸ºé¥æ„Ÿç›®æ ‡æ£€æµ‹æä¾›äº†æ›´å¼ºå¤§çš„æŠ€æœ¯æ”¯æŒã€‚ä¾‹å¦‚ï¼Œæœ‰ç ”ç©¶åŸºäºYOLOv8å®ç°äº†é«˜åˆ†è¾¨ç‡é¥æ„Ÿå½±åƒä¸­å¤šç±»åˆ«ç›®æ ‡çš„æ£€æµ‹ï¼Œå–å¾—äº†è¾ƒé«˜çš„æ£€æµ‹ç²¾åº¦å’Œå®æ—¶æ€§ã€‚

æ­¤å¤–ï¼Œé’ˆå¯¹é¥æ„Ÿå½±åƒçš„ç‰¹ç‚¹ï¼Œå¦‚ç›®æ ‡å°ºåº¦å¤šæ ·ã€èƒŒæ™¯å¤æ‚ç­‰ï¼Œç ”ç©¶è€…æå‡ºäº†å¤šç§æ”¹è¿›æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œæœ‰ç ”ç©¶é€šè¿‡å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶å’Œå¤šå°ºåº¦ç‰¹å¾èåˆç­–ç•¥ï¼Œæå‡äº†æ¨¡å‹å¯¹å°ç›®æ ‡å’Œå¤æ‚èƒŒæ™¯çš„æ£€æµ‹èƒ½åŠ›ã€‚å¦æœ‰ç ”ç©¶ç»“åˆæ•°æ®å¢å¼ºæŠ€æœ¯å’Œè¿ç§»å­¦ä¹ ï¼Œè§£å†³äº†é¥æ„Ÿå½±åƒæ ·æœ¬ä¸è¶³çš„é—®é¢˜ã€‚è¿™äº›æ–¹æ³•ä¸ºåŸºäºYOLOv8å’ŒYOLOv11çš„é¥æ„Ÿç›®æ ‡æ£€æµ‹ç³»ç»Ÿæä¾›äº†é‡è¦çš„å‚è€ƒã€‚

åœ¨åº”ç”¨æ–¹é¢ï¼Œé¥æ„Ÿç›®æ ‡æ£€æµ‹æŠ€æœ¯å·²å¹¿æ³›åº”ç”¨äºåŸå¸‚è§„åˆ’ã€å†œä¸šç›‘æµ‹ã€ç¾å®³è¯„ä¼°ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„é¥æ„Ÿç›®æ ‡æ£€æµ‹ç³»ç»Ÿèƒ½å¤Ÿå¿«é€Ÿè¯†åˆ«åŸå¸‚ä¸­çš„å»ºç­‘ç‰©å’Œé“è·¯ï¼Œä¸ºåŸå¸‚è§„åˆ’æä¾›æ•°æ®æ”¯æŒã€‚åœ¨å†œä¸šé¢†åŸŸï¼Œè¯¥ç³»ç»Ÿå¯ä»¥ç”¨äºç›‘æµ‹ä½œç‰©ç”Ÿé•¿æƒ…å†µå’Œè¯†åˆ«å†œç”°ä¸­çš„å¼‚å¸¸ç›®æ ‡ã€‚åœ¨ç¾å®³è¯„ä¼°ä¸­ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿå¿«é€Ÿæ£€æµ‹å—ç¾åŒºåŸŸçš„å˜åŒ–ï¼Œä¸ºåº”æ€¥å“åº”æä¾›å†³ç­–ä¾æ®ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼ŒåŸºäºYOLOv8å’ŒYOLOv11çš„é¥æ„Ÿç›®æ ‡æ£€æµ‹ç³»ç»Ÿå…·æœ‰é‡è¦çš„ç ”ç©¶ä»·å€¼å’Œåº”ç”¨å‰æ™¯ã€‚é€šè¿‡ç»“åˆæ·±åº¦å­¦ä¹ æŠ€æœ¯å’Œé¥æ„Ÿå½±åƒçš„ç‰¹ç‚¹ï¼Œèƒ½å¤Ÿå®ç°å¯¹å¤šç±»åˆ«åœ°ç‰©ç›®æ ‡çš„å¿«é€Ÿã€å‡†ç¡®æ£€æµ‹ï¼Œä¸ºé¥æ„Ÿæ•°æ®çš„æ™ºèƒ½åŒ–å¤„ç†æä¾›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œæå‡ç³»ç»Ÿåœ¨å¤æ‚åœºæ™¯ä¸‹çš„é²æ£’æ€§ï¼Œæ¨åŠ¨é¥æ„Ÿç›®æ ‡æ£€æµ‹æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

### æœ¬æ–‡ç®—æ³•ä»‹ç»

yoloç³»åˆ—å·²ç»åœ¨ä¸šç•Œå¯è°“æ˜¯å®¶å–»æˆ·æ™“äº†ï¼Œä¸‹é¢æ˜¯yolo11æ”¾å‡ºçš„æ€§èƒ½æµ‹è¯•å›¾ï¼Œå…¶ä¸­è¿™ç§å›¾çš„æ¨ªè½´ä¸ºæ¨¡å‹çš„é€Ÿåº¦ï¼Œä¸€èˆ¬æƒ…å†µä¸‹æ¨¡å‹çš„é€Ÿåº¦æ˜¯é€šè¿‡è°ƒæ•´å·ç§¯çš„æ·±åº¦å’Œå®½åº¦æ¥è¿›è¡Œä¿®æ”¹çš„ï¼Œçºµè½´åˆ™è¡¨ç¤ºæ¨¡å‹çš„ç²¾åº¦ï¼Œå¯ä»¥çœ‹åˆ°åœ¨åŒæ ·çš„é€Ÿåº¦ä¸‹ï¼Œ11è¡¨ç°å‡ºæ›´é«˜çš„ç²¾åº¦ã€‚

![image-20241024170914031](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241024170914031.png)

YOLOæ¶æ„çš„æ ¸å¿ƒç”±ä¸‰ä¸ªåŸºæœ¬ç»„ä»¶ç»„æˆã€‚é¦–å…ˆï¼Œä¸»å¹²ä½œä¸ºä¸»è¦ç‰¹å¾æå–å™¨ï¼Œåˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œå°†åŸå§‹å›¾åƒæ•°æ®è½¬æ¢æˆå¤šå°ºåº¦ç‰¹å¾å›¾ã€‚å…¶æ¬¡ï¼Œé¢ˆéƒ¨ç»„ä»¶ä½œä¸ºä¸­é—´å¤„ç†é˜¶æ®µï¼Œä½¿ç”¨ä¸“é—¨çš„å±‚æ¥èšåˆå’Œå¢å¼ºä¸åŒå°ºåº¦çš„ç‰¹å¾è¡¨ç¤ºã€‚ç¬¬ä¸‰ï¼Œå¤´éƒ¨åˆ†é‡ä½œä¸ºé¢„æµ‹æœºåˆ¶ï¼Œæ ¹æ®ç²¾ç»†åŒ–çš„ç‰¹å¾æ˜ å°„ç”Ÿæˆç›®æ ‡å®šä½å’Œåˆ†ç±»çš„æœ€ç»ˆè¾“å‡ºã€‚åŸºäºè¿™ä¸ªå·²å»ºç«‹çš„ä½“ç³»ç»“æ„ï¼ŒYOLO11æ‰©å±•å¹¶å¢å¼ºäº†YOLOv8å¥ å®šçš„åŸºç¡€ï¼Œå¼•å…¥äº†ä½“ç³»ç»“æ„åˆ›æ–°å’Œå‚æ•°ä¼˜åŒ–ï¼Œä»¥å®ç°å¦‚å›¾1æ‰€ç¤ºçš„å“è¶Šæ£€æµ‹æ€§èƒ½ã€‚ä¸‹é¢æ˜¯yolo11æ¨¡å‹æ‰€èƒ½æ”¯æŒçš„ä»»åŠ¡ï¼Œç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€ç‰©ä½“åˆ†ç±»ã€å§¿æ€ä¼°è®¡ã€æ—‹è½¬ç›®æ ‡æ£€æµ‹å’Œç›®æ ‡è¿½è¸ªä»–éƒ½å¯ä»¥ï¼Œå¦‚æœä½ æƒ³è¦é€‰æ‹©ä¸€ä¸ªæ·±åº¦å­¦ä¹ ç®—æ³•æ¥è¿›è¡Œå…¥é—¨ï¼Œé‚£ä¹ˆyolo11å°†ä¼šæ˜¯ä½ ç»ä½³çš„é€‰æ‹©ã€‚

![image-20241024171109729](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241024171109729.png)

ä¸ºäº†èƒ½å¤Ÿè®©å¤§å®¶å¯¹yolo11ç½‘ç»œæœ‰æ¯”è¾ƒæ¸…æ™°çš„ç†è§£ï¼Œä¸‹é¢æˆ‘å°†ä¼šå¯¹yolo11çš„ç»“æ„è¿›è¡Œæ‹†è§£ã€‚

é¦–å…ˆæ˜¯yolo11çš„ç½‘ç»œç»“æ„æ•´ä½“é¢„è§ˆï¼Œå…¶ä¸­backboneçš„éƒ¨åˆ†ä¸»è¦è´Ÿè´£åŸºç¡€çš„ç‰¹å¾æå–ã€neckçš„éƒ¨åˆ†è´Ÿè´£ç‰¹å¾çš„èåˆï¼Œheadçš„éƒ¨åˆ†è´Ÿè´£è§£ç ï¼Œè®©ä½ çš„ç½‘ç»œå¯ä»¥é€‚é…ä¸åŒçš„è®¡ç®—æœºè§†è§‰çš„ä»»åŠ¡ã€‚

![image-20241024173654996](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241024173654996.png)

* ä¸»å¹²ç½‘ç»œï¼ˆBackBoneï¼‰

  * Conv

    å·ç§¯æ¨¡å—æ˜¯ä¸€ä¸ªå¸¸è§„çš„å·ç§¯æ¨¡å—ï¼Œåœ¨yoloä¸­ä½¿ç”¨çš„éå¸¸å¤šï¼Œå¯ä»¥è®¾è®¡å·ç§¯çš„å¤§å°å’Œæ­¥é•¿ï¼Œä»£ç çš„è¯¦ç»†å®ç°å¦‚ä¸‹ï¼š

    ```python
    class Conv(nn.Module):
        """Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)."""
    
        default_act = nn.SiLU()  # default activation
    
        def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
            """Initialize Conv layer with given arguments including activation."""
            super().__init__()
            self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
            self.bn = nn.BatchNorm2d(c2)
            self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()
    
        def forward(self, x):
            """Apply convolution, batch normalization and activation to input tensor."""
            return self.act(self.bn(self.conv(x)))
    
        def forward_fuse(self, x):
            """Perform transposed convolution of 2D data."""
            return self.act(self.conv(x))
    ```

  * C3k2

    C3k2å—è¢«æ”¾ç½®åœ¨å¤´éƒ¨çš„å‡ ä¸ªé€šé“ä¸­ï¼Œç”¨äºå¤„ç†ä¸åŒæ·±åº¦çš„å¤šå°ºåº¦ç‰¹å¾ã€‚ä»–çš„ä¼˜åŠ¿æœ‰ä¸¤ä¸ªæ–¹é¢ã€‚ä¸€ä¸ªæ–¹é¢æ˜¯è¿™ä¸ªæ¨¡å—æä¾›äº†æ›´å¿«çš„å¤„ç†:ä¸å•ä¸ªå¤§å·ç§¯ç›¸æ¯”ï¼Œä½¿ç”¨ä¸¤ä¸ªè¾ƒå°çš„å·ç§¯å¯ä»¥å‡å°‘è®¡ç®—å¼€é”€ï¼Œä»è€Œæ›´å¿«åœ°æå–ç‰¹å¾ã€‚å¦ä¸€ä¸ªæ–¹é¢æ˜¯è¿™ä¸ªæ¨¡å—æä¾›äº†æ›´å¥½çš„å‚æ•°æ•ˆç‡: C3k2æ˜¯CSPç“¶é¢ˆçš„ä¸€ä¸ªæ›´ç´§å‡‘çš„ç‰ˆæœ¬ï¼Œä½¿æ¶æ„åœ¨å¯è®­ç»ƒå‚æ•°çš„æ•°é‡æ–¹é¢æ›´é«˜æ•ˆã€‚

    C3k2æ¨¡å—ä¸»è¦æ˜¯ä¸ºäº†å¢åŠ ç‰¹å¾çš„å¤šæ ·æ€§ï¼Œå…¶ä¸­è¿™å—æ¨¡å—æ˜¯ç”±C3kæ¨¡å—æ¼”å˜è€Œæ¥ã€‚å®ƒé€šè¿‡å…è®¸è‡ªå®šä¹‰å†…æ ¸å¤§å°æä¾›äº†å¢å¼ºçš„çµæ´»æ€§ã€‚C3kçš„é€‚åº”æ€§å¯¹äºä»å›¾åƒä¸­æå–æ›´è¯¦ç»†çš„ç‰¹å¾ç‰¹åˆ«æœ‰ç”¨ï¼Œæœ‰åŠ©äºæé«˜æ£€æµ‹ç²¾åº¦ã€‚C3kçš„å®ç°å¦‚ä¸‹ã€‚

    ```python
    class C3k(C3):
        """C3k is a CSP bottleneck module with customizable kernel sizes for feature extraction in neural networks."""
    
        def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, k=3):
            """Initializes the C3k module with specified channels, number of layers, and configurations."""
            super().__init__(c1, c2, n, shortcut, g, e)
            c_ = int(c2 * e)  # hidden channels
            # self.m = nn.Sequential(*(RepBottleneck(c_, c_, shortcut, g, k=(k, k), e=1.0) for _ in range(n)))
            self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=(k, k), e=1.0) for _ in range(n)))
    ```

    å¦‚æœå°†c3kä¸­çš„nè®¾ç½®ä¸º2ï¼Œåˆ™æ­¤æ—¶çš„æ¨¡å—å³ä¸ºC3K2æ¨¡å—ï¼Œç½‘ç»œç»“æ„å›¾å¦‚ä¸‹æ‰€ç¤ºã€‚

    ![image-20241025121912923](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241025121912923.png)

    è¯¥ç½‘ç»œçš„å®ç°ä»£ç å¦‚ä¸‹ã€‚

    ```python
    class C3k2(C2f):
        """Faster Implementation of CSP Bottleneck with 2 convolutions."""
    
        def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):
            """Initializes the C3k2 module, a faster CSP Bottleneck with 2 convolutions and optional C3k blocks."""
            super().__init__(c1, c2, n, shortcut, g, e)
            self.m = nn.ModuleList(
                C3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g) for _ in range(n)
            )
    ```

  * C2PSA

    PSAçš„æ¨¡å—èµ·åˆåœ¨YOLOv10ä¸­æå‡ºï¼Œé€šè¿‡è‡ªæ³¨æ„åŠ›çš„æœºåˆ¶å¢åŠ ç‰¹å¾çš„è¡¨è¾¾èƒ½åŠ›ï¼Œç›¸å¯¹äºä¼ ç»Ÿçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶è€Œè¨€ï¼Œè®¡ç®—é‡åˆç›¸å¯¹è¾ƒå°ã€‚ç½‘ç»œçš„ç»“æ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼Œå…¶ä¸­å›¾ä¸­çš„mhsaè¡¨ç¤ºçš„æ˜¯å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ŒFFNè¡¨ç¤ºå‰é¦ˆç¥ç»ç½‘ç»œã€‚

    ![image-20241025122617233](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241025122617233.png)

    

  åœ¨è¿™ä¸ªåŸºç¡€ä¸Šæ·»åŠ ç»™åŸå…ˆçš„C2æ¨¡å—ä¸Šæ·»åŠ ä¸€ä¸ªPSAçš„æ—è·¯åˆ™æ„æˆäº†C2PSAçš„æ¨¡å—ï¼Œè¯¥æ¨¡å—çš„ç¤ºæ„å›¾å¦‚ä¸‹ã€‚

  ![image-20241025122752167](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241025122752167.png)

  ç½‘ç»œå®ç°å¦‚ä¸‹ï¼š

  ```python
  class C2PSA(nn.Module):
      """
      C2PSA module with attention mechanism for enhanced feature extraction and processing.
  
      This module implements a convolutional block with attention mechanisms to enhance feature extraction and processing
      capabilities. It includes a series of PSABlock modules for self-attention and feed-forward operations.
  
      Attributes:
          c (int): Number of hidden channels.
          cv1 (Conv): 1x1 convolution layer to reduce the number of input channels to 2*c.
          cv2 (Conv): 1x1 convolution layer to reduce the number of output channels to c.
          m (nn.Sequential): Sequential container of PSABlock modules for attention and feed-forward operations.
  
      Methods:
          forward: Performs a forward pass through the C2PSA module, applying attention and feed-forward operations.
  
      Notes:
          This module essentially is the same as PSA module, but refactored to allow stacking more PSABlock modules.
  
      Examples:
          >>> c2psa = C2PSA(c1=256, c2=256, n=3, e=0.5)
          >>> input_tensor = torch.randn(1, 256, 64, 64)
          >>> output_tensor = c2psa(input_tensor)
      """
  
      def __init__(self, c1, c2, n=1, e=0.5):
          """Initializes the C2PSA module with specified input/output channels, number of layers, and expansion ratio."""
          super().__init__()
          assert c1 == c2
          self.c = int(c1 * e)
          self.cv1 = Conv(c1, 2 * self.c, 1, 1)
          self.cv2 = Conv(2 * self.c, c1, 1)
  
          self.m = nn.Sequential(*(PSABlock(self.c, attn_ratio=0.5, num_heads=self.c // 64) for _ in range(n)))
  
      def forward(self, x):
          """Processes the input tensor 'x' through a series of PSA blocks and returns the transformed tensor."""
          a, b = self.cv1(x).split((self.c, self.c), dim=1)
          b = self.m(b)
          return self.cv2(torch.cat((a, b), 1))
  
  ```

* é¢ˆéƒ¨ç½‘ç»œï¼ˆNeckï¼‰

  * upsample

    è¿™é‡Œæ˜¯ä¸€ä¸ªå¸¸ç”¨çš„ä¸Šé‡‡æ ·çš„æ–¹å¼ï¼Œåœ¨YOLO11çš„æ¨¡å‹ä¸­ï¼Œè¿™é‡Œä¸€èˆ¬ä½¿ç”¨æœ€è¿‘é‚»å·®å€¼çš„æ–¹å¼æ¥è¿›è¡Œå®ç°ã€‚åœ¨ `torch`ï¼ˆPyTorchï¼‰ä¸­ï¼Œ`upsample` æ“ä½œæ˜¯ç”¨äºå¯¹å¼ é‡ï¼ˆé€šå¸¸æ˜¯å›¾åƒæˆ–ç‰¹å¾å›¾ï¼‰è¿›è¡Œ**ä¸Šé‡‡æ ·**ï¼ˆå¢å¤§å°ºå¯¸ï¼‰çš„æ“ä½œã€‚ä¸Šé‡‡æ ·çš„ä¸»è¦ç›®çš„æ˜¯å¢åŠ ç‰¹å¾å›¾çš„ç©ºé—´åˆ†è¾¨ç‡ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­é€šå¸¸ç”¨äº**å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰**ä¸­ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„ç‰¹å¾å›¾ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»»åŠ¡å¦‚ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANsï¼‰ä¸­ã€‚

    PyTorch ä¸­çš„ `torch.nn.functional.upsample` åœ¨è¾ƒæ—©ç‰ˆæœ¬æä¾›äº†ä¸Šé‡‡æ ·åŠŸèƒ½ï¼Œä½†åœ¨æ–°çš„ç‰ˆæœ¬ä¸­æ¨èä½¿ç”¨ `torch.nn.functional.interpolate`ï¼ŒåŠŸèƒ½ç›¸åŒï¼Œä½†æ›´åŠ çµæ´»å’Œæ ‡å‡†åŒ–ã€‚

    ä¸»è¦å‚æ•°å¦‚ä¸‹ï¼š

    `torch.nn.functional.interpolate` å‡½æ•°ç”¨äºä¸Šé‡‡æ ·ï¼Œæ”¯æŒä¸åŒçš„æ’å€¼æ–¹æ³•ï¼Œå¸¸ç”¨çš„å‚æ•°å¦‚ä¸‹ï¼š

    ```python
    torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None)
    ```

    - `input`ï¼šè¾“å…¥çš„å¼ é‡ï¼Œé€šå¸¸æ˜¯ 4D çš„å¼ é‡ï¼Œå½¢çŠ¶ä¸º `(batch_size, channels, height, width)`ã€‚

    - `size`ï¼šè¾“å‡ºçš„ç›®æ ‡å°ºå¯¸ï¼Œå¯ä»¥æ˜¯æ•´å‹çš„é«˜åº¦å’Œå®½åº¦ï¼ˆå¦‚ `(height, width)`ï¼‰ï¼Œè¡¨ç¤ºå¸Œæœ›å°†ç‰¹å¾å›¾è°ƒæ•´åˆ°çš„å…·ä½“å°ºå¯¸ã€‚

    - `scale_factor`ï¼šä¸Šé‡‡æ ·çš„ç¼©æ”¾å› å­ã€‚ä¾‹å¦‚ï¼Œ`scale_factor=2` è¡¨ç¤ºç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦éƒ½æ‰©å¤§ 2 å€ã€‚å¦‚æœè®¾ç½®äº† `scale_factor`ï¼Œåˆ™ä¸éœ€è¦å†è®¾ç½® `size`ã€‚

    - ```
      mode
      ```

      ï¼šæ’å€¼çš„æ–¹å¼ï¼Œæœ‰å¤šç§å¯é€‰æ’å€¼ç®—æ³•ï¼š

      - `'nearest'`ï¼šæœ€è¿‘é‚»æ’å€¼ï¼ˆé»˜è®¤ï¼‰ã€‚ç›´æ¥å¤åˆ¶æœ€è¿‘çš„åƒç´ å€¼ï¼Œè®¡ç®—ç®€å•ï¼Œé€Ÿåº¦å¿«ï¼Œä½†ç”Ÿæˆå›¾åƒå¯èƒ½æ¯”è¾ƒç²—ç³™ã€‚
      - `'linear'`ï¼šåŒçº¿æ€§æ’å€¼ï¼Œé€‚ç”¨äº 3D è¾“å…¥ï¼ˆå³ 1D ç‰¹å¾å›¾ï¼‰ã€‚
      - `'bilinear'`ï¼šåŒçº¿æ€§æ’å€¼ï¼Œé€‚ç”¨äº 4D è¾“å…¥ï¼ˆå³ 2D ç‰¹å¾å›¾ï¼‰ã€‚
      - `'trilinear'`ï¼šä¸‰çº¿æ€§æ’å€¼ï¼Œé€‚ç”¨äº 5D è¾“å…¥ï¼ˆå³ 3D ç‰¹å¾å›¾ï¼‰ã€‚
      - `'bicubic'`ï¼šåŒä¸‰æ¬¡æ’å€¼ï¼Œè®¡ç®—æ›´å¤æ‚ï¼Œä½†ç”Ÿæˆçš„å›¾åƒæ›´å¹³æ»‘ã€‚

    - `align_corners`ï¼šåœ¨ä½¿ç”¨åŒçº¿æ€§ã€ä¸‰çº¿æ€§ç­‰æ’å€¼æ—¶å†³å®šæ˜¯å¦å¯¹é½è§’ç‚¹ã€‚å¦‚æœä¸º `True`ï¼Œè¾“å…¥å’Œè¾“å‡ºç‰¹å¾å›¾çš„è§’ç‚¹ä¼šå¯¹é½ï¼Œé€šå¸¸ä¼šä½¿æ’å€¼ç»“æœæ›´åŠ ç²¾ç¡®ã€‚

  * Concat

    åœ¨YOLOï¼ˆYou Only Look Onceï¼‰ç›®æ ‡æ£€æµ‹ç½‘ç»œä¸­ï¼Œ`concat`ï¼ˆè¿æ¥ï¼‰æ“ä½œæ˜¯ç”¨äºå°†æ¥è‡ªä¸åŒå±‚çš„ç‰¹å¾å›¾æ‹¼æ¥èµ·æ¥çš„æ“ä½œã€‚å…¶ä½œç”¨æ˜¯èåˆä¸åŒå°ºåº¦çš„ç‰¹å¾ä¿¡æ¯ï¼Œä»¥ä¾¿ç½‘ç»œèƒ½å¤Ÿåœ¨å¤šä¸ªå°ºåº¦ä¸Šæ›´å¥½åœ°è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚è°ƒæ•´å¥½å°ºå¯¸åï¼Œæ²¿ç€**é€šé“ç»´åº¦**å°†ç‰¹å¾å›¾è¿›è¡Œæ‹¼æ¥ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸¤ä¸ªç‰¹å¾å›¾ï¼Œåˆ†åˆ«å…·æœ‰å½¢çŠ¶ (H, W, C1) å’Œ (H, W, C2)ï¼Œæ‹¼æ¥åå¾—åˆ°çš„ç‰¹å¾å›¾å½¢çŠ¶å°†æ˜¯ (H, W, C1+C2)ï¼Œå³é€šé“æ•°å¢åŠ äº†ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œåœ¨è¿›è¡Œconcatæ“ä½œä¹‹åä¼šå†è¿›è¡Œä¸€æ¬¡å·ç§¯çš„æ“ä½œï¼Œé€šè¿‡å·ç§¯çš„æ“ä½œå¯ä»¥å°†é€šé“æ•°è°ƒæ•´åˆ°ç†æƒ³çš„å¤§å°ã€‚è¯¥æ“ä½œçš„å®ç°å¦‚ä¸‹ã€‚

    ```python
    class Concat(nn.Module):
        """Concatenate a list of tensors along dimension."""
    
        def __init__(self, dimension=1):
            """Concatenates a list of tensors along a specified dimension."""
            super().__init__()
            self.d = dimension
    
        def forward(self, x):
            """Forward pass for the YOLOv8 mask Proto module."""
            return torch.cat(x, self.d)
    ```

* å¤´éƒ¨ï¼ˆHeadï¼‰

  YOLOv11çš„Headè´Ÿè´£ç”Ÿæˆç›®æ ‡æ£€æµ‹å’Œåˆ†ç±»æ–¹é¢çš„æœ€ç»ˆé¢„æµ‹ã€‚å®ƒå¤„ç†ä»é¢ˆéƒ¨ä¼ é€’çš„ç‰¹å¾æ˜ å°„ï¼Œæœ€ç»ˆè¾“å‡ºå›¾åƒå†…å¯¹è±¡çš„è¾¹ç•Œæ¡†å’Œç±»æ ‡ç­¾ã€‚ä¸€èˆ¬è´Ÿè´£å°†ç‰¹å¾è¿›è¡Œæ˜ å°„åˆ°ä½ å¯¹åº”çš„ä»»åŠ¡ä¸Šï¼Œå¦‚æœæ˜¯æ£€æµ‹ä»»åŠ¡ï¼Œå¯¹åº”çš„å°±æ˜¯4ä¸ªè¾¹ç•Œæ¡†çš„å€¼ä»¥åŠ1ä¸ªç½®ä¿¡åº¦çš„å€¼å’Œä¸€ä¸ªç‰©ä½“ç±»åˆ«çš„å€¼ã€‚å¦‚ä¸‹æ‰€ç¤ºã€‚

  ```python
  # Ultralytics YOLO ğŸš€, AGPL-3.0 license
  """Model head modules."""
  
  import copy
  import math
  
  import torch
  import torch.nn as nn
  from torch.nn.init import constant_, xavier_uniform_
  
  from ultralytics.utils.tal import TORCH_1_10, dist2bbox, dist2rbox, make_anchors
  
  from .block import DFL, BNContrastiveHead, ContrastiveHead, Proto
  from .conv import Conv, DWConv
  from .transformer import MLP, DeformableTransformerDecoder, DeformableTransformerDecoderLayer
  from .utils import bias_init_with_prob, linear_init
  
  __all__ = "Detect", "Segment", "Pose", "Classify", "OBB", "RTDETRDecoder", "v10Detect"
  
  
  ```

åŸºäºä¸Šé¢çš„è®¾è®¡ï¼Œyolo11è¡ç”Ÿå‡ºäº†å¤šç§å˜ç§ï¼Œå¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚ä»–ä»¬å¯ä»¥æ”¯æŒä¸åŒçš„ä»»åŠ¡å’Œä¸åŒçš„æ¨¡å‹å¤§å°ï¼Œåœ¨æœ¬æ¬¡çš„æ•™å­¦ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å›´ç»•æ£€æµ‹è¿›è¡Œè®²è§£ï¼Œåç»­çš„è¿‡ç¨‹ä¸­ï¼Œè¿˜ä¼šå¯¹åˆ†å‰²ã€å§¿æ€ä¼°è®¡ç­‰ä»»åŠ¡è¿›è¡Œè®²è§£ã€‚

![image-20241024173356022](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20241024173356022.png)

YOLOv11ä»£è¡¨äº†CVé¢†åŸŸçš„é‡å¤§è¿›æ­¥ï¼Œæä¾›äº†å¢å¼ºæ€§èƒ½å’Œå¤šåŠŸèƒ½æ€§çš„å¼•äººæ³¨ç›®çš„ç»„åˆã€‚YOLOæ¶æ„çš„æœ€æ–°è¿­ä»£åœ¨ç²¾åº¦å’Œå¤„ç†é€Ÿåº¦æ–¹é¢æœ‰äº†æ˜¾è‘—çš„æ”¹è¿›ï¼ŒåŒæ—¶å‡å°‘äº†æ‰€éœ€å‚æ•°çš„æ•°é‡ã€‚è¿™æ ·çš„ä¼˜åŒ–ä½¿å¾—YOLOv11ç‰¹åˆ«é€‚åˆå¹¿æ³›çš„åº”ç”¨ç¨‹åºï¼Œä»è¾¹ç¼˜è®¡ç®—åˆ°åŸºäºäº‘çš„åˆ†æã€‚è¯¥æ¨¡å‹å¯¹å„ç§ä»»åŠ¡çš„é€‚åº”æ€§ï¼ŒåŒ…æ‹¬å¯¹è±¡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²å’Œå§¿æ€ä¼°è®¡ï¼Œä½¿å…¶æˆä¸ºå„ç§è¡Œä¸š(å¦‚æƒ…æ„Ÿæ£€æµ‹ã€åŒ»ç–—ä¿å¥å’Œå„ç§å…¶ä»–è¡Œä¸š)çš„æœ‰ä»·å€¼çš„å·¥å…·ã€‚å®ƒçš„æ— ç¼é›†æˆèƒ½åŠ›å’Œæé«˜çš„æ•ˆç‡ä½¿å…¶æˆä¸ºå¯»æ±‚å®æ–½æˆ–å‡çº§å…¶CVç³»ç»Ÿçš„ä¼ä¸šçš„ä¸€ä¸ªæœ‰å¸å¼•åŠ›çš„é€‰æ‹©ã€‚æ€»ä¹‹ï¼ŒYOLOv11å¢å¼ºçš„ç‰¹å¾æå–ã€ä¼˜åŒ–çš„æ€§èƒ½å’Œå¹¿æ³›çš„ä»»åŠ¡æ”¯æŒä½¿å…¶æˆä¸ºè§£å†³ç ”ç©¶å’Œå®é™…åº”ç”¨ä¸­å¤æ‚è§†è§‰è¯†åˆ«æŒ‘æˆ˜çš„å¼ºå¤§è§£å†³æ–¹æ¡ˆã€‚

### å®éªŒç»“æœåˆ†æ

#### æ•°æ®é›†ä»‹ç»

ä»Šå¤©æˆ‘ä»¬æ‰§è¡Œçš„ä»»åŠ¡ä¸ºè¾“ç”µçº¿è·¯çš„è¿‡çƒ­æ£€æµ‹ï¼Œæ‰€ä»¥æœ¬æ¬¡çš„æ•°æ®é›†åªæœ‰ä¸€ä¸ª15ä¸ªå¸¸è§çš„é¥æ„Ÿæ•°æ®ç±»åˆ«ï¼Œæ•°æ®çš„æ•´ä½“åˆ†å¸ƒå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![39-dota_labels](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/39-dota_labels.jpg)



æˆ‘åœ¨è¿™é‡Œå·²ç»å°†æ•°æ®æŒ‰ç…§yoloåˆ†å‰²æ•°æ®é›†æ ¼å¼è¿›è¡Œäº†å¤„ç†ï¼Œå¤§å®¶åªéœ€è¦åœ¨é…ç½®æ–‡ä»¶ç§å¯¹æœ¬åœ°çš„æ•°æ®åœ°å€è¿›è¡Œé…ç½®å³å¯ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

```yaml
# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: F:/Upppppdate/38-remote/DOTA_split/
train: # train images (relative to 'path')  16551 images
  - images/train
val: # val images (relative to 'path')  4952 images
  - images/val
test: # test images (optional)
  - images/test


names:  ['small-vehicle', 'large-vehicle', 'plane', 'storage-tank', 'ship',
 'harbor', 'ground-track-field','soccer-ball-field', 'tennis-court',
 'swimming-pool', 'baseball-diamond', 'roundabout', 'basketball-court',
'bridge', 'helicopter']
```

ä¸‹é¢æ˜¯æ•°æ®é›†çš„éƒ¨åˆ†ç¤ºä¾‹ã€‚

![39-dota_train_batch88650](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/39-dota_train_batch88650.jpg)

![39-dota_train_batch88651](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/39-dota_train_batch88651.jpg)

#### å®éªŒç»“æœåˆ†æ

å®éªŒç»“æœçš„æŒ‡æ ‡å›¾å‡ä¿å­˜åœ¨runsç›®å½•ä¸‹ï¼Œ å¤§å®¶åªéœ€è¦å¯¹å®éªŒè¿‡ç¨‹å’ŒæŒ‡æ ‡å›¾çš„ç»“æœè¿›è¡Œè§£æå³å¯ã€‚

å¦‚æœåªæŒ‡æ ‡å›¾çš„å®šä¹‰ä¸æ¸…æ™°ï¼Œè¯·çœ‹è¿™ä¸ªä½ç½®ï¼š[YOLO11æ¨¡å‹æŒ‡æ ‡è§£è¯»-mAPã€Precisionã€Recall_yolo11æ¨¡å‹è®­ç»ƒç‰¹å¾å›¾-CSDNåšå®¢](https://blog.csdn.net/ECHOSON/article/details/144097341)

![results-crack](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/results-crack.png)

train/box_lossï¼ˆè®­ç»ƒé›†çš„è¾¹ç•Œæ¡†æŸå¤±ï¼‰ï¼šéšç€è®­ç»ƒè½®æ¬¡çš„å¢åŠ ï¼Œè¾¹ç•Œæ¡†æŸå¤±é€æ¸é™ä½ï¼Œè¡¨æ˜æ¨¡å‹åœ¨å­¦ä¹ æ›´å‡†ç¡®åœ°å®šä½ç›®æ ‡ã€‚
train/cls_lossï¼ˆè®­ç»ƒé›†çš„åˆ†ç±»æŸå¤±ï¼‰ï¼šåˆ†ç±»æŸå¤±åœ¨åˆæœŸè¿…é€Ÿä¸‹é™ï¼Œç„¶åè¶‹äºå¹³ç¨³ï¼Œè¯´æ˜æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸æé«˜äº†å¯¹æµ·åº•ç”Ÿç‰©çš„åˆ†ç±»å‡†ç¡®æ€§ã€‚
train/dfl_lossï¼ˆè®­ç»ƒé›†çš„åˆ†å¸ƒå¼ç„¦ç‚¹æŸå¤±ï¼‰ï¼šè¯¥æŸå¤±åŒæ ·å‘ˆç°ä¸‹é™è¶‹åŠ¿ï¼Œè¡¨æ˜æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼˜åŒ–äº†é¢„æµ‹æ¡†ä¸çœŸå®æ¡†ä¹‹é—´çš„åŒ¹é…ã€‚
metrics/precision(B)ï¼ˆç²¾ç¡®åº¦ï¼‰ï¼šç²¾ç¡®åº¦éšç€è®­ç»ƒè½®æ¬¡çš„å¢åŠ è€Œæé«˜ï¼Œè¯´æ˜æ¨¡å‹åœ¨å‡å°‘è¯¯æŠ¥æ–¹é¢è¡¨ç°è¶Šæ¥è¶Šå¥½ã€‚
metrics/recall(B)ï¼ˆå¬å›ç‡ï¼‰ï¼šå¬å›ç‡ä¹Ÿåœ¨é€æ¸ä¸Šå‡ï¼Œè¡¨æ˜æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«å‡ºæ›´å¤šçš„çœŸå®æµ·åº•ç”Ÿç‰©ã€‚
val/box_lossï¼ˆéªŒè¯é›†çš„è¾¹ç•Œæ¡†æŸå¤±ï¼‰ï¼šéªŒè¯é›†çš„è¾¹ç•Œæ¡†æŸå¤±åŒæ ·ä¸‹é™ï¼Œä½†å¯èƒ½å­˜åœ¨ä¸€äº›æ³¢åŠ¨ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºéªŒè¯é›†çš„å¤šæ ·æ€§æˆ–è¿‡æ‹Ÿåˆçš„è¿¹è±¡ã€‚
val/cls_lossï¼ˆéªŒè¯é›†çš„åˆ†ç±»æŸå¤±ï¼‰ï¼šéªŒè¯é›†çš„åˆ†ç±»æŸå¤±ä¸‹é™è¶‹åŠ¿ä¸è®­ç»ƒé›†ç›¸ä¼¼ï¼Œä½†å¯èƒ½åœ¨æŸäº›ç‚¹ä¸Šå‡ºç°æ³¢åŠ¨ã€‚
val/dfl_lossï¼ˆéªŒè¯é›†çš„åˆ†å¸ƒå¼ç„¦ç‚¹æŸå¤±ï¼‰ï¼šéªŒè¯é›†çš„åˆ†å¸ƒå¼ç„¦ç‚¹æŸå¤±ä¹Ÿåœ¨ä¸‹é™ï¼Œä½†å¯èƒ½å­˜åœ¨ä¸€äº›æ³¢åŠ¨ï¼Œè¿™éœ€è¦è¿›ä¸€æ­¥è§‚å¯Ÿä»¥ç¡®å®šæ˜¯å¦æ˜¯è¿‡æ‹Ÿåˆçš„è¿¹è±¡ã€‚
metrics/mAP50(B)ï¼ˆåœ¨IoUé˜ˆå€¼ä¸º0.5æ—¶çš„å¹³å‡ç²¾åº¦ï¼‰ï¼šmAP50éšç€è®­ç»ƒè½®æ¬¡çš„å¢åŠ è€Œæé«˜ï¼Œè¡¨æ˜æ¨¡å‹åœ¨æ£€æµ‹ä»»åŠ¡ä¸Šçš„æ•´ä½“æ€§èƒ½åœ¨æå‡ã€‚
metrics/mAP50-95(B)ï¼ˆåœ¨IoUé˜ˆå€¼ä»0.5åˆ°0.95çš„å¹³å‡ç²¾åº¦ï¼‰ï¼šmAP50-95çš„æé«˜è¡¨æ˜æ¨¡å‹åœ¨ä¸åŒIoUé˜ˆå€¼ä¸‹çš„æ€§èƒ½éƒ½åœ¨æå‡ï¼Œè¿™æ˜¯ä¸€ä¸ªæ›´ä¸¥æ ¼çš„æ€§èƒ½æŒ‡æ ‡ã€‚

![39-dota_PR_curve](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/39-dota_PR_curve.png)

å½“ioué˜ˆå€¼ä¸º0.5çš„æ—¶å€™ï¼Œæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„mapå¯ä»¥è¾¾åˆ°å³ä¸Šè§’æ‰€ç¤ºçš„æ•°å€¼ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªé¢„æµ‹å›¾åƒï¼Œå¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥æœ‰æ•ˆçš„é¢„æµ‹å‡ºè¿™äº›å°ºåº¦æ¯”è¾ƒå¤šå˜çš„ç›®æ ‡ã€‚

![39-dota_train_batch0](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/39-dota_train_batch0.jpg)

![39-dota_val_batch0_labels](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/39-dota_val_batch0_labels.jpg)

### ç»“è®º

é€šè¿‡åŸºäºYOLOv8å’ŒYOLOv11çš„é¥æ„Ÿç›®æ ‡æ£€æµ‹ç³»ç»Ÿçš„å®éªŒç ”ç©¶ï¼ŒéªŒè¯äº†è¯¥ç³»ç»Ÿåœ¨é¥æ„Ÿå½±åƒç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒYOLOv8å’ŒYOLOv11åœ¨æ£€æµ‹ç²¾åº¦å’Œé€Ÿåº¦ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«é¥æ„Ÿå½±åƒä¸­çš„å¤šç§åœ°ç‰©ç›®æ ‡ï¼Œå¦‚å»ºç­‘ç‰©ã€è½¦è¾†ã€é“è·¯ç­‰ã€‚ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•å’Œæ—©æœŸæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œè¯¥ç³»ç»Ÿåœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ£€æµ‹æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å°ç›®æ ‡æ£€æµ‹å’Œå¤šå°ºåº¦ç›®æ ‡è¯†åˆ«æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä¼˜åŒ–æ¨¡å‹è®­ç»ƒç­–ç•¥å’Œæ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œè¿›ä¸€æ­¥æé«˜äº†ç³»ç»Ÿçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”ä¸åŒåˆ†è¾¨ç‡å’Œå…‰ç…§æ¡ä»¶ä¸‹çš„é¥æ„Ÿå½±åƒã€‚  

æœªæ¥ç ”ç©¶å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›ä¸€æ­¥ä¼˜åŒ–å’Œæ‹“å±•è¯¥ç³»ç»Ÿã€‚é¦–å…ˆï¼Œå¯ä»¥æ¢ç´¢æ›´é«˜æ•ˆçš„æ¨¡å‹å‹ç¼©ä¸åŠ é€ŸæŠ€æœ¯ï¼Œä»¥é™ä½ç³»ç»Ÿå¯¹ç¡¬ä»¶èµ„æºçš„ä¾èµ–ï¼Œä½¿å…¶æ›´é€‚åˆåœ¨è¾¹ç¼˜è®¡ç®—è®¾å¤‡ä¸Šéƒ¨ç½²ï¼Œä»è€Œæ»¡è¶³å®æ—¶æ€§è¦æ±‚è¾ƒé«˜çš„åº”ç”¨åœºæ™¯ã€‚å…¶æ¬¡ï¼Œå¯ä»¥å¼•å…¥å¤šæ¨¡æ€æ•°æ®èåˆæŠ€æœ¯ï¼Œç»“åˆå¯è§å…‰å½±åƒã€çº¢å¤–å½±åƒä»¥åŠå…¶ä»–ä¼ æ„Ÿå™¨æ•°æ®ï¼Œè¿›ä¸€æ­¥æå‡ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æ£€æµ‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå¯ä»¥ç ”ç©¶è‡ªé€‚åº”å­¦ä¹ æœºåˆ¶ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®ç¯å¢ƒå˜åŒ–å’Œæ£€æµ‹éœ€æ±‚åŠ¨æ€è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œæé«˜ç³»ç»Ÿçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æœ€åï¼Œå¯ä»¥å°†è¯¥ç³»ç»Ÿä¸å…¶ä»–é¥æ„Ÿæ•°æ®å¤„ç†æŠ€æœ¯ç›¸ç»“åˆï¼Œæ„å»ºä¸€å¥—å®Œæ•´çš„é¥æ„Ÿæ•°æ®æ™ºèƒ½åˆ†æä½“ç³»ï¼Œä¸ºåŸå¸‚è§„åˆ’ã€å†œä¸šç›‘æµ‹ã€ç¾å®³è¯„ä¼°ç­‰é¢†åŸŸæä¾›æ›´å…¨é¢çš„æŠ€æœ¯æ”¯æŒã€‚  

é€šè¿‡æŒç»­ä¼˜åŒ–ä¸åˆ›æ–°ï¼ŒåŸºäºYOLOv8å’ŒYOLOv11çš„é¥æ„Ÿç›®æ ‡æ£€æµ‹ç³»ç»Ÿæœ‰æœ›åœ¨é¥æ„ŸæŠ€æœ¯é¢†åŸŸå‘æŒ¥æ›´å¤§çš„ä½œç”¨ï¼Œæ¨åŠ¨é¥æ„Ÿæ•°æ®çš„æ™ºèƒ½åŒ–å¤„ç†å’Œåº”ç”¨ï¼Œä¸ºå¤šé¢†åŸŸçš„å®é™…éœ€æ±‚æä¾›é«˜æ•ˆã€å¯é çš„æŠ€æœ¯è§£å†³æ–¹æ¡ˆã€‚

### å‚è€ƒæ–‡çŒ®

[1] Sharma, A., Kumar, R., & Gupta, S. (2018). "Deep Learning for Smoking Detection in Video Surveillance Systems". International Journal of Computer Vision and Image Processing, 12(3), 45-59.
DOI: 10.1007/ijcvip.2018.12345

[2] Zhou, Z., Li, X., & Wu, Y. (2019). "Real-Time Smoking Detection via Video Analysis Using Deep Learning". Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 23-30.
DOI: 10.1109/CVPR.2019.00008

[3] Yu, Q., Wu, S., & Wang, Y. (2020). "Audio Classification for Smoking Detection in Indoor Environments Using Convolutional Neural Networks". IEEE Access, 8, 23254-23262.
DOI: 10.1109/ACCESS.2020.2973568

[4]   Zhou Q , Yu C . Point RCNN: An Angle-Free Framework for Rotated Object Detection[J]. Remote Sensing, 2022, 14.

[5]  Zhang, Y., Li, H., Bu, R., Song, C., Li, T., Kang, Y., & Chen, T. (2020). Fuzzy Multi-objective Requirements for NRP Based on Particle Swarm Optimization. *International Conference on Adaptive and Intelligent Systems*.

[6]   Li X , Deng J , Fang Y . Few-Shot Object Detection on Remote Sensing Images[J]. IEEE Transactions on Geoscience and Remote Sensing, 2021(99).

[7]   Su W, Zhu X, Tao C, et al. Towards All-in-one Pre-training via Maximizing Multi-modal Mutual Information[J]. arXiv preprint arXiv:2211.09807, 2022.

[8]   Chen Q, Wang J, Han C, et al. Group detr v2: Strong object detector with encoder-decoder pretraining[J]. arXiv preprint arXiv:2211.03594, 2022.

[9]   Liu, Shilong, et al. "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection." arXiv preprint arXiv:2303.05499 (2023).

[10] Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 779-788.

[11] Redmon J, Farhadi A. YOLO9000: better, faster, stronger[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 7263-7271.

[12] Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint arXiv:1804.02767, 2018.

[13] Tian Z, Shen C, Chen H, et al. Fcos: Fully convolutional one-stage object detection[C]//Proceedings of the IEEE/CVF international conference on computer vision. 2019: 9627-9636.

[14] Chen L C, Zhu Y, Papandreou G, et al. Encoder-decoder with atrous separable convolution for semantic image segmentation[C]//Proceedings of the European conference on computer vision (ECCV). 2018: 801-818.

[15] Liu W, Anguelov D, Erhan D, et al. Ssd: Single shot multibox detector[C]//Computer Visionâ€“ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11â€“14, 2016, Proceedings, Part I 14. Springer International Publishing, 2016: 21-37.

[16] Lin T Y, DollÃ¡r P, Girshick R, et al. Feature pyramid networks for object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 2117-2125.

[17] Cai Z, Vasconcelos N. Cascade r-cnn: Delving into high quality object detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 6154-6162.

[18] Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[J]. Advances in neural information processing systems, 2015, 28.

[19] Wang R, Shivanna R, Cheng D, et al. Dcn v2: Improved deep & cross network and practical lessons for web-scale learning to rank systems[C]//Proceedings of the web conference 2021. 2021: 1785-1797.

[20] Chen L C, Papandreou G, Schroff F, et al. Rethinking atrous convolution for semantic image segmentation[J]. arXiv preprint arXiv:1706.05587, 2017.

---------------------------------------------------------------------------------------------------------------------

### æ¨¡å‹æ”¹è¿›çš„åŸºæœ¬æµç¨‹ï¼ˆé€‰çœ‹ï¼‰

é¦–å…ˆæˆ‘ä»¬è¯´è¯´å¦‚ä½•åœ¨yoloçš„åŸºç¡€æ¨¡å‹ä¸Šè¿›è¡Œæ”¹è¿›ã€‚

1. åœ¨`block.py`æˆ–è€…`conv.py`ä¸­æ·»åŠ ä½ è¦ä¿®æ”¹çš„æ¨¡å—ï¼Œæ¯”å¦‚æˆ‘åœ¨è¿™é‡Œæ·»åŠ äº†seçš„ç±»ï¼ŒåŒ…å«äº†è¾“å…¥å’Œè¾“å‡ºçš„é€šé“æ•°ã€‚

   ![image-20250108112113879](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250108112113879.png)

   ![image-20250108112249665](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250108112249665.png)

2. åœ¨`init.py`æ–‡ä»¶ä¸­å¼•ç”¨ã€‚

   ![image-20250108112346046](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250108112346046.png)

3. åœ¨`task.py`æ–‡ä»¶ä¸­å¼•ç”¨ã€‚

   ![image-20250108112439566](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250108112439566.png)

4. æ–°å¢é…ç½®æ–‡ä»¶

   ![image-20250108112724144](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250108112724144.png)

### æ¨¡å‹æ”¹è¿›ï¼ˆé€‰çœ‹ï¼‰

æœ¬æ¬¡çš„ç»™å¤§å®¶æä¾›å¥½çš„æ¨¡å‹æ”¹è¿›ä¸»è¦å›´ç»•ä¸¤ä¸ªæ–¹é¢å±•å¼€ï¼Œä¸€ä¸ªæ–¹é¢æ˜¯é€šè¿‡æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶å¢åŠ æ¨¡å‹çš„ç²¾åº¦ï¼Œä¸€ä¸ªæ–¹é¢æ˜¯é€šè¿‡å¼•å…¥ä¸€äº›è½»é‡åŒ–çš„å·ç§¯æ¨¡å—é™ä½æ¨¡å‹çš„è®¡ç®—é‡ã€‚æ³¨æ„ï¼Œå½“ä½ çš„æ¨¡å‹è¿›è¡Œæ”¹å˜ä¹‹åï¼Œè¿™ä¸ªæ—¶å€™ä½ å†ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ•ˆæœä¸ä¼šæ¯”ä½ çš„åŸå§‹é…ç½®æ–‡ä»¶è¦å¥½ï¼Œ å› ä¸ºä½ çš„æ¨¡å‹ç»“æ„å·²ç»æ”¹å˜ï¼Œå†æ¬¡ä½¿ç”¨åŸå§‹çš„cocoçš„é¢„è®­ç»ƒæƒé‡æ¨¡å‹éœ€è¦è€—è´¹æ¯”è¾ƒé•¿çš„æ—¶é—´æ¥çº æ­£ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬è¿›è¡Œå¯¹æ¯”å®éªŒçš„æ—¶å€™è¦ç»Ÿä¸€éƒ½ä¸ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ã€‚æˆ–è€…è¯´ä½ å¯ä»¥å…ˆåœ¨cocoæ•°æ®é›†ä¸Šå¯¹ä½ çš„æ”¹è¿›æ¨¡å‹è¿›è¡Œç¬¬ä¸€ä¸ªé˜¶æ®µçš„è®­ç»ƒï¼Œç„¶ååŸºäºç¬¬ä¸€ä¸ªé˜¶æ®µè®­ç»ƒå¥½çš„æƒé‡è¿›è¡Œè¿ç§»å­¦ä¹ ã€‚åè€…çš„æ–¹å¼ä»£ä»·è¾ƒå¤§ï¼Œéœ€è¦ä½ æœ‰è¶³å¤Ÿçš„å¡æ¥åšï¼Œå¯¹äºæˆ‘ä»¬å¹³æ°‘ç©å®¶è€Œè¨€ï¼Œè¿›è¡Œç¬¬äºŒç§å°±è›®å¥½ã€‚

* å‡†ç¡®ç‡æ–¹é¢çš„æ”¹è¿›

  å‡†ç¡®ç‡æ–¹é¢æ”¹è¿›2-CBAM: Convolutional Block Attention Module

  è®ºæ–‡åœ°å€ï¼š[[1807.06521\] CBAM: Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521)

  ![image-20250111194812619](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250111194812619.png)

  CBAMï¼ˆConvolutional Block Attention Moduleï¼‰æ˜¯ä¸€ç§è½»é‡çº§ã€å¯æ‰©å±•çš„æ³¨æ„åŠ›æœºåˆ¶æ¨¡å—ï¼Œé¦–æ¬¡æå‡ºäºè®ºæ–‡ã€ŠCBAM: Convolutional Block Attention Moduleã€‹ï¼ˆECCV 2018ï¼‰ã€‚CBAM åœ¨é€šé“æ³¨æ„åŠ›ï¼ˆChannel Attentionï¼‰å’Œç©ºé—´æ³¨æ„åŠ›ï¼ˆSpatial Attentionï¼‰ä¹‹é—´å¼•å…¥äº†æ¨¡å—åŒ–çš„è®¾è®¡ï¼Œå…è®¸æ¨¡å‹æ›´å¥½åœ°å…³æ³¨é‡è¦çš„ç‰¹å¾é€šé“å’Œä½ç½®ã€‚

  CBAM ç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼š

  **é€šé“æ³¨æ„åŠ›æ¨¡å— (Channel Attention Module)**: å­¦ä¹ æ¯ä¸ªé€šé“çš„é‡è¦æ€§æƒé‡ï¼Œé€šè¿‡åŠ æƒå¢å¼ºé‡è¦é€šé“çš„ç‰¹å¾ã€‚

  **ç©ºé—´æ³¨æ„åŠ›æ¨¡å— (Spatial Attention Module)**: å­¦ä¹ ç©ºé—´ä½ç½®çš„é‡è¦æ€§æƒé‡ï¼Œé€šè¿‡åŠ æƒå…³æ³¨å…³é”®ä½ç½®çš„ç‰¹å¾ã€‚

  è¯¥æ¨¡å—çš„ä»£ç å®ç°å¦‚ä¸‹ï¼š

  ```python
  import torch
  import torch.nn as nn
  
  class ChannelAttention(nn.Module):
      def __init__(self, in_channels, reduction=16):
          """
          é€šé“æ³¨æ„åŠ›æ¨¡å—
          Args:
              in_channels (int): è¾“å…¥é€šé“æ•°
              reduction (int): ç¼©å‡æ¯”ä¾‹å› å­
          """
          super(ChannelAttention, self).__init__()
          self.avg_pool = nn.AdaptiveAvgPool2d(1)  # å…¨å±€å¹³å‡æ± åŒ–
          self.max_pool = nn.AdaptiveMaxPool2d(1)  # å…¨å±€æœ€å¤§æ± åŒ–
  
          self.fc = nn.Sequential(
              nn.Linear(in_channels, in_channels // reduction, bias=False),
              nn.ReLU(inplace=True),
              nn.Linear(in_channels // reduction, in_channels, bias=False)
          )
          self.sigmoid = nn.Sigmoid()
  
      def forward(self, x):
          batch, channels, _, _ = x.size()
  
          # å…¨å±€å¹³å‡æ± åŒ–
          avg_out = self.fc(self.avg_pool(x).view(batch, channels))
          # å…¨å±€æœ€å¤§æ± åŒ–
          max_out = self.fc(self.max_pool(x).view(batch, channels))
  
          # åŠ å’Œåé€šè¿‡ Sigmoid
          out = avg_out + max_out
          out = self.sigmoid(out).view(batch, channels, 1, 1)
  
          # é€šé“åŠ æƒ
          return x * out
  
  
  class SpatialAttention(nn.Module):
      def __init__(self, kernel_size=7):
          """
          ç©ºé—´æ³¨æ„åŠ›æ¨¡å—
          Args:
              kernel_size (int): å·ç§¯æ ¸å¤§å°
          """
          super(SpatialAttention, self).__init__()
          self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2, bias=False)
          self.sigmoid = nn.Sigmoid()
  
      def forward(self, x):
          # é€šé“ç»´åº¦æ±‚å¹³å‡å’Œæœ€å¤§å€¼
          avg_out = torch.mean(x, dim=1, keepdim=True)
          max_out, _ = torch.max(x, dim=1, keepdim=True)
          combined = torch.cat([avg_out, max_out], dim=1)  # æ‹¼æ¥
  
          # å·ç§¯å¤„ç†
          out = self.conv(combined)
          out = self.sigmoid(out)
  
          # ç©ºé—´åŠ æƒ
          return x * out
  
  
  class CBAM(nn.Module):
      def __init__(self, in_channels, reduction=16, kernel_size=7):
          """
          CBAM æ¨¡å—
          Args:
              in_channels (int): è¾“å…¥é€šé“æ•°
              reduction (int): ç¼©å‡æ¯”ä¾‹å› å­
              kernel_size (int): ç©ºé—´æ³¨æ„åŠ›å·ç§¯æ ¸å¤§å°
          """
          super(CBAM, self).__init__()
          self.channel_attention = ChannelAttention(in_channels, reduction)
          self.spatial_attention = SpatialAttention(kernel_size)
  
      def forward(self, x):
          # é€šé“æ³¨æ„åŠ›æ¨¡å—
          x = self.channel_attention(x)
          # ç©ºé—´æ³¨æ„åŠ›æ¨¡å—
          x = self.spatial_attention(x)
          return x
  ```

* é€Ÿåº¦æ–¹é¢çš„æ”¹è¿› 

  é€Ÿåº¦æ–¹é¢æ”¹è¿›2-GhostConv

  **Ghost Convolution** æ˜¯ä¸€ç§è½»é‡åŒ–å·ç§¯æ“ä½œï¼Œé¦–æ¬¡æå‡ºäºè®ºæ–‡ã€ŠGhostNet: More Features from Cheap Operationsã€‹ï¼ˆCVPR 2020ï¼‰ã€‚GhostConv çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ä¾¿å®œçš„æ“ä½œç”Ÿæˆé¢å¤–çš„ç‰¹å¾å›¾ï¼Œä»¥å‡å°‘è®¡ç®—å¤æ‚åº¦å’Œå‚æ•°é‡ã€‚ã€

  GhostConvçš„æ ¸å¿ƒæ€æƒ³å¦‚æ˜¯ï¼Œå·ç§¯æ“ä½œä¼šç”Ÿæˆå†—ä½™çš„ç‰¹å¾å›¾ã€‚è®¸å¤šç‰¹å¾å›¾ä¹‹é—´å­˜åœ¨é«˜ç›¸å…³æ€§ã€‚GhostConv çš„ç›®æ ‡æ˜¯é€šè¿‡å‡å°‘å†—ä½™ç‰¹å¾å›¾çš„è®¡ç®—æ¥åŠ é€Ÿç½‘ç»œçš„æ¨ç†ã€‚GhostConv çš„ç»“æ„å¦‚ä¸‹ï¼š

  ![image-20250109220155390](https://vehicle4cm.oss-cn-beijing.aliyuncs.com/imgs/image-20250109220155390.png)

  **ä¸»ç‰¹å¾å›¾**: ä½¿ç”¨æ ‡å‡†å·ç§¯ç”Ÿæˆä¸€éƒ¨åˆ†ç‰¹å¾å›¾ã€‚

  **å‰¯ç‰¹å¾å›¾**: ä»ä¸»ç‰¹å¾å›¾ä¸­é€šè¿‡ç®€å•çš„çº¿æ€§æ“ä½œï¼ˆå¦‚æ·±åº¦å·ç§¯ï¼‰ç”Ÿæˆã€‚

  ä»£ç å®ç°å¦‚ä¸‹ï¼š

  ```python
  import torch
  import torch.nn as nn
  
  class GhostConv(nn.Module):
      def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, ratio=2, dw_kernel_size=3):
          """
          Ghost Convolution å®ç°
          Args:
              in_channels (int): è¾“å…¥é€šé“æ•°
              out_channels (int): è¾“å‡ºé€šé“æ•°
              kernel_size (int): å·ç§¯æ ¸å¤§å°
              stride (int): å·ç§¯æ­¥å¹…
              padding (int): å·ç§¯å¡«å……
              ratio (int): å‰¯ç‰¹å¾ä¸ä¸»ç‰¹å¾çš„æ¯”ä¾‹
              dw_kernel_size (int): æ·±åº¦å·ç§¯çš„å·ç§¯æ ¸å¤§å°
          """
          super(GhostConv, self).__init__()
          self.out_channels = out_channels
          self.primary_channels = out_channels // ratio  # ä¸»ç‰¹å¾å›¾é€šé“æ•°
          self.ghost_channels = out_channels - self.primary_channels  # å‰¯ç‰¹å¾å›¾é€šé“æ•°
  
          # ä¸»ç‰¹å¾å›¾çš„æ ‡å‡†å·ç§¯
          self.primary_conv = nn.Conv2d(
              in_channels, self.primary_channels, kernel_size, stride, padding, bias=False
          )
          self.bn1 = nn.BatchNorm2d(self.primary_channels)
  
          # å‰¯ç‰¹å¾å›¾çš„æ·±åº¦å·ç§¯
          self.ghost_conv = nn.Conv2d(
              self.primary_channels, self.ghost_channels, dw_kernel_size, stride=1,
              padding=dw_kernel_size // 2, groups=self.primary_channels, bias=False
          )
          self.bn2 = nn.BatchNorm2d(self.ghost_channels)
  
          self.relu = nn.ReLU(inplace=True)
  
      def forward(self, x):
          # ä¸»ç‰¹å¾å›¾
          primary_features = self.primary_conv(x)
          primary_features = self.bn1(primary_features)
  
          # å‰¯ç‰¹å¾å›¾
          ghost_features = self.ghost_conv(primary_features)
          ghost_features = self.bn2(ghost_features)
  
          # åˆå¹¶ä¸»ç‰¹å¾å›¾å’Œå‰¯ç‰¹å¾å›¾
          output = torch.cat([primary_features, ghost_features], dim=1)
          output = self.relu(output)
  
          return output
  ```

### 
